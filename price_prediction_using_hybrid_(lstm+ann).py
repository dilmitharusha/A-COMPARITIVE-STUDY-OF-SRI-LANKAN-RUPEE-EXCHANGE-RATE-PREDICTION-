# -*- coding: utf-8 -*-
"""Price Prediction Using Hybrid (LSTM+ANN).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1x-V0IbAhDRtfXw9zEhoeVezgnpMB7GdG
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
# %matplotlib inline
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import keras
import seaborn as sns
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.svm import SVR
from sklearn.model_selection import GridSearchCV


from google.colab import drive

#mounting google drive
drive.mount('/content/drive')

#Reading dataset
data = pd.read_csv('/content/drive/MyDrive/MathsProject/USD_LKR Historical Data.csv')

data.index=pd.to_datetime(data['Date'])
data.index = data.index.date

data

#removing unwanted columns from dataset
del data['Change %']
del data['Date']

#validation dataset
data=data.iloc[:-100]
data_val=data.iloc[-100:]

#making column headers lower case in order to easy use
data.columns=[c.lower() for c in data.columns]
data_val.columns=[c.lower() for c in data_val.columns]

#checking for null values
null_values=data.isnull()
print(f'{null_values.sum()} Null values')
print(null_values)

# Removing rows with null values
data = data.dropna()
print("\nDataFrame after removing rows with null values:")
print(data)

# Removing rows with zero values
data = data[~(data == 0).any(axis=1)]
print("\nDataFrame after removing rows with zero values:")
print(data)

early_stopping = EarlyStopping(
    monitor='loss',   # Metric to monitor (usually validation loss)
    patience=5,          # Number of epochs with no improvement after which training will be stopped
    restore_best_weights=True   # Restore the best model weights when training stops
)

# Split the dataset into input features (X) and target variable (y)
X = data[['open', 'high', 'low',]]
y = data['price']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)
#X_train_lstm, X_test_lstm, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)

# Standardize the input features
scaler = StandardScaler()

# Scale the training data and testing data
X_train = scaler.fit_transform(X_train)
X_test = scaler.fit_transform(X_test)

#X_train_lstm = scaler.fit_transform(X_train_lstm)
#X_test_lstm = scaler.fit_transform(X_test_lstm)

X_train

#X_train_lstm

#X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])
#X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])

# Reshape input data for LSTM
X_train_lstm = X_train_lstm.reshape((X_train_lstm.shape[0], 1, X_train_lstm.shape[1]))
X_test_lstm = X_test_lstm.reshape((X_test_lstm.shape[0], 1, X_test_lstm.shape[1]))

model = keras.Sequential()
model.add(keras.layers.LSTM(50, input_shape=(1, X_train_lstm.shape[2])))
model.add(keras.layers.Dense(1))

model.compile(optimizer='adam', loss='mse')
# model.summary()

model.fit(X_train_lstm, y_train, epochs=150, batch_size=4, callbacks=[early_stopping])

# Make predictions using the LSTM model
y_pred_lstm = model.predict(X_test_lstm)

# Build and train the ANN model
ann_model = keras.Sequential([
    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    layers.Dropout(0.2),
    layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),
    layers.Dropout(0.1),
    layers.Dense(1)
])

ann_model.compile(optimizer='adam', loss='mean_squared_error')
early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=5,
    restore_best_weights=True
)

trained_ann_model = ann_model.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_test, y_test), callbacks=[early_stopping])

# Make predictions using the ANN model
y_pred_ann = ann_model.predict(X_test)

# Concatenate the predictions from both models
X_test_hybrid = np.concatenate((y_pred_lstm, y_pred_ann), axis=1)

# Build the final hybrid model
hybrid_model = keras.Sequential([layers.Dense(64, activation='relu', input_shape=(2,)),layers.Dense(1)
])
hybrid_model.compile(optimizer='adam', loss='mean_squared_error')

# Train the final hybrid model
hybrid_model.fit(X_test_hybrid, y_test, epochs=50, batch_size=8)

# Make predictions using the final hybrid model
y_pred_hybrid = hybrid_model.predict(X_test_hybrid)

# Calculate and print evaluation metrics
mse = mean_squared_error(y_test, y_pred_hybrid)
mae = mean_absolute_error(y_test, y_pred_hybrid)
r2 = r2_score(y_test, y_pred_hybrid)
print(f"Mean Squared Error: {mse:.3f}")
print(f"Mean Absolute Error: {mae:.3f}")
print(f"R-squared: {r2:.3f}")

y_test[:10]

y_pred_hybrid[:10]

# Create a DataFrame with date indices from y_test
results_df = pd.DataFrame(index=y_test.index)

results_df['y_test'] = y_test.values
results_df['hybrid_predictions'] = y_pred_hybrid

results_df

import matplotlib.pyplot as plt

# Create a scatter plot to compare actual vs. predicted values
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred_hybrid, color='blue', label='Actual vs. Predicted')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2, color='red', label='Perfectly Predicted')
plt.xlabel('Actual Prices')
plt.ylabel('Predicted Prices')
plt.title('Actual vs. Predicted Prices (Hybrid Model(ANN+LSTM))')
plt.legend()
plt.show()