# -*- coding: utf-8 -*-
"""Price Prediction hybrid Model(SVR+LSTM).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kEypUtvW9pBNJ33jqOFBt6jXCnFr64up
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
# %matplotlib inline
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import keras
import seaborn as sns
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.svm import SVR
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LinearRegression


from google.colab import drive

#mounting google drive
drive.mount('/content/drive')

#Reading dataset
data = pd.read_csv('/content/drive/MyDrive/MathsProject/USD_LKR Historical Data.csv')

data.index=pd.to_datetime(data['Date'])
data.index = data.index.date

data

#removing unwanted columns from dataset
del data['Change %']
del data['Date']

#validation dataset
data=data.iloc[:-100]
data_val=data.iloc[-100:]

#making column headers lower case in order to easy use
data.columns=[c.lower() for c in data.columns]
data_val.columns=[c.lower() for c in data_val.columns]

#checking for null values
null_values=data.isnull()
print(f'{null_values.sum()} Null values')
print(null_values)

# Removing rows with null values
data = data.dropna()
print("\nDataFrame after removing rows with null values:")
print(data)

# Removing rows with zero values
data = data[~(data == 0).any(axis=1)]
print("\nDataFrame after removing rows with zero values:")
print(data)

early_stopping = EarlyStopping(
    monitor='loss',   # Metric to monitor (usually validation loss)
    patience=5,          # Number of epochs with no improvement after which training will be stopped
    restore_best_weights=True   # Restore the best model weights when training stops
)

# Split the dataset into input features (X) and target variable (y)
X = data[['open', 'high', 'low',]]
y = data['price']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)
#X_train_lstm, X_test_lstm, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)

# Standardize the input features
scaler = StandardScaler()

# Scale the training data and testing data
X_train = scaler.fit_transform(X_train)
X_test = scaler.fit_transform(X_test)

#X_train_lstm = scaler.fit_transform(X_train_lstm)
#X_test_lstm = scaler.fit_transform(X_test_lstm)

X_train

#X_train_lstm

#X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])
#X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])

# Reshape input data for LSTM
X_train_lstm = X_train_lstm.reshape((X_train_lstm.shape[0], 1, X_train_lstm.shape[1]))
X_test_lstm = X_test_lstm.reshape((X_test_lstm.shape[0], 1, X_test_lstm.shape[1]))

model = keras.Sequential()
model.add(keras.layers.LSTM(50, input_shape=(1, X_train_lstm.shape[2])))
model.add(keras.layers.Dense(1))

model.compile(optimizer='adam', loss='mse')
# model.summary()

model.fit(X_train_lstm, y_train, epochs=150, batch_size=4, callbacks=[early_stopping])

# Make predictions using the LSTM model
y_pred_lstm = model.predict(X_test_lstm)

"""SVR"""

# Define hyperparameters for SVR model (you can use the best hyperparameters obtained from grid search)
svr_params = {'C': 1000, 'kernel': 'rbf', 'gamma': 0.00001}

# Create an SVR model
svr_model = SVR(**svr_params)

# Fit the SVR model on the training data
svr_model.fit(X_train, y_train)

# Predict on the test set using SVR
y_svr_pred = svr_model.predict(X_test)

# Create a new training set with predictions from base models
X_train_stacked = np.column_stack((y_pred_lstm.flatten(), y_svr_pred))

# Create a new testing set with predictions from base models
X_test_stacked = np.column_stack((model.predict(X_test_lstm).flatten(), svr_model.predict(X_test)))

from sklearn.linear_model import LinearRegression

# Train a meta-model (Linear Regression) on the stacked predictions
meta_model = LinearRegression()
meta_model.fit(X_train_stacked, y_test)

# Make predictions using the meta-model
y_hybrid_pred = meta_model.predict(X_test_stacked)

# Evaluate the performance of the hybrid model
hybrid_mse = mean_squared_error(y_test, y_hybrid_pred)
hybrid_mae = mean_absolute_error(y_test, y_hybrid_pred)
hybrid_r2 = r2_score(y_test, y_hybrid_pred)

print("Hybrid Model Metrics:")
print(f"Mean Squared Error (MSE): {hybrid_mse:.2f}")
print(f"Mean Absolute Error (MAE): {hybrid_mae:.2f}")
print(f"R-squared (R2): {hybrid_r2:.2f}")

y_test[:10]

y_hybrid_pred[:10]

# Create a DataFrame with date indices from y_test
results_df = pd.DataFrame(index=y_test.index)

results_df['y_test'] = y_test.values
results_df['hybrid_predictions'] = y_hybrid_pred

results_df

import matplotlib.pyplot as plt

# Create a scatter plot to compare actual vs. predicted values
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_hybrid_pred, color='blue', label='Actual vs. Predicted')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2, color='red', label='Perfectly Predicted')
plt.xlabel('Actual Prices')
plt.ylabel('Predicted Prices')
plt.title('Actual vs. Predicted Prices (Hybrid Model(SVR+LSTM))')
plt.legend()
plt.show()

